import hdf5storage
import os
import numpy as np
import xarray as xr


def _calculate_ea(t_air_celcius, rh):
    """Internal function that calculates the actual vapour pressure (kPa) from the
    air temperature (degree Celcius) and relative humidity (%)

    Args:
        t_air_celcius: numpy array containing the air temperature in degrees C.

        rh: numpy array of same shape as t_air_celcius, containing the relative humidity
            as a percentage (e.g. ranging from 0 - 100).

    Returns:
        numpy array with the calculated actual vapor pressure
    """
    # es = 6.107 * 10**(t_air_celcius*7.5 / (237.3+t_air_celcius))
    es = 0.61 * np.exp(19.9*t_air_celcius/(273+t_air_celcius))
    return es * rh/100


def _write_matlab_ascii(fname, data, ncols):
    """Internal function to handle writing data in the Matlab ascii format. Equivalent
    to `save([-], '-ascii')` in Matlab.

    Args:
        fname (path or str): Path to the file that should be written
        data (np.array): Array with data to write to file
        ncols (int, optional): The number of data columns, required to correctly format
            the ascii file when writing multiple variables.
    """
    matlab_fmt = ' %14.7e'
    multi_fmt = [matlab_fmt]*ncols
    multi_fmt[0] = ' ' + multi_fmt[0]
    np.savetxt(fname, data, multi_fmt)


def read_forcing_data(forcing_file):
    """Reads the forcing data from the provided netCDF file, and applies the required
    unit conversions before returning the read data.

    Args:
        forcing_file (str or path): Path to the netCDF file containing the forcing data

    Returns:
        dict: Dictionary containing the different variables required by STEMMUS_SCOPE
            for the different forcing files.
    """
    ds_forcing = xr.open_dataset(forcing_file)

    # remove the x and y coordinates from the data variables to make the numpy arrays 1D
    ds_forcing = ds_forcing.squeeze(['x', 'y'])

    data = {}
    # Expected time format is days (as floating point) since Jan 1st 00:00.
    data['doy_float'] = (
        ds_forcing['time'].dt.dayofyear - 1 +
        ds_forcing['time'].dt.hour/24 +
        ds_forcing['time'].dt.minute/60/24
    )
    data['year'] = ds_forcing['time'].dt.year.astype(float)

    data['t_air_celcius'] = ds_forcing['Tair'] - 273.15
    # convert air pressure from Pa to hPa
    data['psurf_hpa'] = ds_forcing['Psurf'] / 100

    # convert CO2 concentration from 'mole fraction' to ?
    data['co2_conv'] = ds_forcing['CO2air'] * 44 / 22.4

    # convert precipitation from [kg/m2/s] to ?
    data['precip_conv'] = ds_forcing['Precip'] / 10

    data['lw_down'] = ds_forcing['LWdown']
    data['sw_down'] = ds_forcing['SWdown']
    data['wind_speed'] = ds_forcing['Wind']
    data['rh'] = ds_forcing['RH']
    data['vpd'] = ds_forcing['VPD']

    data['lai'] = ds_forcing['LAI']
    data['lai'][data['lai']<0.01] = 0.01

    data['ea'] = _calculate_ea(data['t_air_celcius'], data['rh'])

    return data


def write_dat_files(data, input_dir):
    """Fuction to write the single-data .dat files for the STEMMUS_SCOPE matlab model.

    Args:
        data (dict): Data dictionary generated by read_forcing
        input_dir (path or str): Directory to which the different single-column .dat
            files should be written to.
    """
    write_info = {
        'doy_float': 't_.dat',
        't_air_celcius': 'Ta_.dat',
        'sw_down': 'Rin_.dat',
        'lw_down': 'Rli_.dat',
        'psurf_hpa': 'p_.dat',
        'wind_speed': 'u_.dat',
        'co2_conv': 'CO2_.dat',
        'ea': 'ea_.dat',
        'year': 'year_.dat'
    }
    for var, fname in write_info.items():
        fpath = os.path.join(input_dir, fname)
        _write_matlab_ascii(fpath, data[var], ncols=1)


def write_lai_file(data, fname):
    lai_file_data = np.vstack([data['doy_float'], data['lai']]).T
    _write_matlab_ascii(fname, lai_file_data, ncols=2)


def write_meteo_file(data, fname):
    meteo_data_vars = ['doy_float', 't_air_celcius', 'rh',
        'wind_speed', 'psurf_hpa', 'precip_conv', 'sw_down',
        'lw_down', 'vpd', 'lai']
    meteo_file_data = np.vstack([data[var] for var in meteo_data_vars]).T
    _write_matlab_ascii(fname, meteo_file_data, ncols=len(meteo_data_vars))


def prepare_global_variables(forcing_file, config, input_dir):
    ds = xr.open_dataset(forcing_file)
    ds = ds.squeeze(['x', 'y'])
    sitename = forcing_file.split('/')[-1][:6]
    time_delta = (ds.time.dt.second[1] - ds.time.dt.second[1]).values

    if config['DurationSize'] > ds.time.size:
        total_duration = ds.time.size
    else:
        total_duration = config['DurationSize']

    matfiledata = {
        'latitude': ds['latitude'].values,
        'longitude': ds['longitude'].values,
        'elevation': ds['elevation'].values,
        'IGBP_veg_long': ds['IGBP_veg_long'].values,
        'reference_height': ds['reference_height'].values,
        'canopy_height': ds['canopy_height'].values,
        'Dur_tot': total_duration,
        'DELT': time_delta,
        'sitename': sitename
    }

    hdf5storage.write(
        matfiledata, input_dir, 'forcing_globals.mat', matlab_compatible=True)


def prepare_forcing(input_dir, forcing_file):
    """Function to prepare the forcing files required by STEMMUS_SCOPE. The input
        directory should be taken from the model configuration file.

    Args:
        input_dir (path or str): Path to the input directory that will be read by
            STEMMUS_SCOPE.
        forcing_file (path or str): Path to the netCDF forcing file that will be used
            to generate the input data.
    """
    data = read_forcing_data(forcing_file)
    write_dat_files(data, input_dir)
    write_meteo_file(data, os.path.join(input_dir, 'Mdata.txt'))
    write_lai_file(data, os.path.join(input_dir, 'LAI_.dat'))
