{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the STEMMUS_SCOPE model\n",
    "Steps to run the STEMMUS_SCOPE model, including preprocessing and postprocessing, on Surf super computer Snellius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an executable file of STEMMUS_SCOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to executable\n",
    "root_path_to_model = Path(Path.home(), \"STEMMUS_SCOPE\")\n",
    "# submit slurm job if the executable does not exist\n",
    "if not Path(root_path_to_model, \"exe\", \"STEMMUS_SCOPE\").is_file():\n",
    "    result = subprocess.run([\"sbatch\", \"build_stemmus_scope_exe.sh\"], cwd = Path(root_path_to_model, \"exe\"))\n",
    "    result.check_returncode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update/set config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The listed paths are defined in the config file:\n",
      "SoilPropertyPath\n",
      "InputPath\n",
      "OutputPath\n",
      "ForcingPath\n",
      "ForcingFileName\n",
      "VegetationPropertyPath\n",
      "DurationSize\n"
     ]
    }
   ],
   "source": [
    "# the user must provide the correct path\n",
    "path_dict = {\n",
    "    \"SoilPropertyPath\": \"/projects/0/einf2480/model_parameters/soil_property/\",\n",
    "    \"InputPath\": \"/scratch-shared/ecoextreml/stemmus_scope/test/input/\",\n",
    "    \"OutputPath\": \"/scratch-shared/ecoextreml/stemmus_scope/test/output/\",\n",
    "    \"ForcingPath\": \"/projects/0/einf2480/forcing/plumber2_data/\",\n",
    "    \"ForcingFileName\": \"FI-Hyy_1996-2014_FLUXNET2015_Met.nc\",\n",
    "    \"VegetationPropertyPath\": \"/projects/0/einf2480/model_parameters/vegetation_property/\",\n",
    "    \"DurationSize\": \"20\"\n",
    "}\n",
    "\n",
    "# generate a text file\n",
    "root_path = Path().resolve().parent\n",
    "\n",
    "with open(Path(root_path, \"config_file_snellius.txt\"), 'w') as f:\n",
    "    print(\"The listed paths are defined in the config file:\")\n",
    "    for i in path_dict.keys():\n",
    "        print(i)\n",
    "        f.write((i + \"=\" + path_dict[i] + \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create input directories, prepare input files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dir(station_name):\n",
    "    \"\"\"Create input directory and prepare input files\n",
    "    \"\"\"\n",
    "    # get start time with the format Y-M-D-HM\n",
    "    start_time = str(datetime.datetime.now()).split('.')[0]\n",
    "    timestamp = start_time.replace(' ', '-').replace(':', '')[:-2]\n",
    "    # create input directory\n",
    "    work_dir = Path(path_dict[\"InputPath\"], station_name + '_' + timestamp)\n",
    "    Path(work_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Prepare work directory for the station: {station_name}\")\n",
    "    # copy model parameters to work directory\n",
    "    shutil.copytree(path_dict[\"VegetationPropertyPath\"], work_dir, dirs_exist_ok=True)\n",
    "    # update config file for ForcingFileName and InputPath\n",
    "    with open(Path(work_dir, f\"{station_name}_{timestamp}_config.txt\"), 'w') as f:\n",
    "        for i in path_dict.keys():\n",
    "            if i == \"ForcingFileName\":\n",
    "                f.write(i + \"=\" + ncfile.stem + \".nc\" + \"\\n\")\n",
    "            elif i == \"InputPath\":\n",
    "                f.write(i + \"=\" + str(work_dir) + \"/\" + \"\\n\")\n",
    "            else:\n",
    "                f.write(i + \"=\" + path_dict[i] + \"\\n\")\n",
    "    \n",
    "    # create an output file\n",
    "    Path(root_path, \"out\").mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(root_path, \"out\", f\"{station_name}.out\"), 'w') as f:\n",
    "        for i in path_dict.keys():\n",
    "            if i == \"ForcingFileName\":\n",
    "                f.write(i + \" is \" + ncfile.stem + \".nc\" + \"\\n\")\n",
    "            elif i == \"InputPath\":\n",
    "                f.write(i + \" is \" + str(work_dir) + \"/\" + \"\\n\")\n",
    "            elif i == \"DurationSize\":\n",
    "                pass\n",
    "            else:\n",
    "                f.write(i + \" is \" + path_dict[i] + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare work directory for the station: NL-Hor\n",
      "Prepare work directory for the station: ZA-Kru\n"
     ]
    }
   ],
   "source": [
    "# specify the station of interest\n",
    "# station_names_list is by default none, if it is not specified, then all stations with forcing\n",
    "# listed in the ForcingPath will be used.\n",
    "#station_names_list = None\n",
    "station_names_list = [\"NL-Hor\", \"ZA-Kru\"]\n",
    "\n",
    "for ncfile in Path(path_dict[\"ForcingPath\"]).iterdir():\n",
    "    # get the station name\n",
    "    station_name = ncfile.stem.split('_')[0]\n",
    "    # check if a station list is provided\n",
    "    if station_names_list == None:\n",
    "        input_dir(station_name)\n",
    "    elif station_name in station_names_list:\n",
    "        input_dir(station_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening log file:  /gpfs/home3/yangl/processing/out/java.log.8605\n",
      "Reading config from /scratch-shared/ecoextreml/stemmus_scope/test/input/ZA-Kru_2022-05-10-1135/ZA-Kru_2022-05-10-1135_config.txt\n",
      "\n",
      " The calculations start now \n",
      "Opening log file:  /gpfs/home3/yangl/processing/out/java.log.9641\n",
      "Reading config from /scratch-shared/ecoextreml/stemmus_scope/test/input/NL-Hor_2022-05-10-1135/NL-Hor_2022-05-10-1135_config.txt\n",
      "\n",
      " The calculations start now \n",
      " The calculations end now \r"
     ]
    }
   ],
   "source": [
    "for station_dir in os.listdir(path_dict[\"InputPath\"]):\n",
    "    station_name = station_dir.split(\"_\")[0]\n",
    "    path_to_config = Path(path_dict[\"InputPath\"], f\"{station_dir}\",f\"{station_dir}_config.txt\")\n",
    "    # set matlab log dir to slurm, otherwise java.log files are created in user home dir\n",
    "    os.environ['MATLAB_LOG_DIR'] = f'{Path(root_path, \"out\")}'\n",
    "    # start time\n",
    "    start_time = time.time()\n",
    "    # run the model\n",
    "    print(f\"Run STEMMUS-SCOPE for the station: {station_name}\")\n",
    "    result = subprocess.run([f\"exe/STEMMUS_SCOPE {path_to_config}\", \">>\", f\"{station_name}.out\"], cwd = root_path_to_model, shell=True)\n",
    "    result.check_returncode()\n",
    "    # calculate total execution time\n",
    "    run_time = time.time() - start_time\n",
    "    # add execution information to out file\n",
    "    with open(Path(root_path, \"out\", f\"{station_name}.out\"), 'a') as f:\n",
    "        f.write(f\"Run is COMPLETED. Model run time is {run_time} s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create output directories, prepare output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch-shared/ecoextreml/stemmus_scope/test/output/ZA-Kru_2022-05-10-1135/ECdata.csv\n",
      "Reading variable metadata from /home/yangl/STEMMUS_SCOPE/utils/csv_to_nc/Variables_will_be_in_NetCDF_file.csv\n",
      "Creating /scratch-shared/ecoextreml/stemmus_scope/test/output/ZA-Kru_2022-05-10-1135/ZA-Kru_2022-05-10-1135_STEMMUS_SCOPE.nc \n",
      "Reading data from file: radiation.csv\n",
      "Reading data from file: fluxes.csv\n",
      "Reading data from file: surftemp.csv\n",
      "Reading data from file: Sim_Temp.csv\n",
      "Reading data from file: Sim_Theta.csv\n",
      "Reading data from file: aerodyn.csv\n",
      "Reading data from file: ECdata.csv\n",
      "Done writing /scratch-shared/ecoextreml/stemmus_scope/test/output/ZA-Kru_2022-05-10-1135/ZA-Kru_2022-05-10-1135_STEMMUS_SCOPE.nc\n",
      "/scratch-shared/ecoextreml/stemmus_scope/test/output/NL-Hor_2022-05-10-1136/ECdata.csv\n",
      "Reading variable metadata from /home/yangl/STEMMUS_SCOPE/utils/csv_to_nc/Variables_will_be_in_NetCDF_file.csv\n",
      "Creating /scratch-shared/ecoextreml/stemmus_scope/test/output/NL-Hor_2022-05-10-1136/NL-Hor_2022-05-10-1136_STEMMUS_SCOPE.nc \n",
      "Reading data from file: radiation.csv\n",
      "Reading data from file: fluxes.csv\n",
      "Reading data from file: surftemp.csv\n",
      "Reading data from file: Sim_Temp.csv\n",
      "Reading data from file: Sim_Theta.csv\n",
      "Reading data from file: aerodyn.csv\n",
      "Reading data from file: ECdata.csv\n",
      "Done writing /scratch-shared/ecoextreml/stemmus_scope/test/output/NL-Hor_2022-05-10-1136/NL-Hor_2022-05-10-1136_STEMMUS_SCOPE.nc\n"
     ]
    }
   ],
   "source": [
    "# convert csv files to nc files\n",
    "path_to_utils = Path(root_path_to_model, \"utils/csv_to_nc\")\n",
    "for station_dir in os.listdir(path_dict[\"InputPath\"]):\n",
    "    path_to_config = Path(path_dict[\"InputPath\"], f\"{station_dir}\",f\"{station_dir}_config.txt\")\n",
    "    result = subprocess.run([\"python\", Path(path_to_utils, \"generate_netcdf_files.py\"),\n",
    "         \"--config_file\", path_to_config, \"--variable_file\", Path(path_to_utils, \"Variables_will_be_in_NetCDF_file.csv\")])\n",
    "    result.check_returncode()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28b136f154b3384fcb2854e5626613232692c304dbc5315064ef4c9363104a2c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
