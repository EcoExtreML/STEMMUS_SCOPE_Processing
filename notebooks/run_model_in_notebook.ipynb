{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the STEMMUS_SCOPE model\n",
    "Steps to run the STEMMUS_SCOPE model, including preprocessing and postprocessing, on Surf super computer Snellius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an executable file of STEMMUS_SCOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to executable\n",
    "root_path_to_model = Path(Path.home(), \"EcoExtreML\", \"STEMMUS_SCOPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell if:\n",
    "- You are a developer of the model and you have already changed some of the MATLAB scripts.\n",
    "- Make sure that you are on the right branch of STEMMUS_SCOPE repository.\n",
    "\n",
    "Users on Snellius should be able to use MATLAB on Snellius and you must add the following command to [this bash script](https://github.com/EcoExtreML/processing/blob/main/run_jupyter_lab_on_compute_node.sh):<br>\n",
    "`module load MATLAB/2021a-upd3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-creating the exe file\n",
    "result = subprocess.run([\"mcc\", \"-m\", \"./src/STEMMUS_SCOPE_exe.m\", \"-a\", \"./src\", \"-d\",\n",
    "    \"./exe\", \"-o\", \"STEMMUS_SCOPE\", \"-R\", \"nodisplay\", \"-R\", \"singleCompThread\"],\n",
    "    cwd = Path(root_path_to_model, \"exe\"))\n",
    "result.check_returncode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update/set config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SoilPropertyPath': '/projects/0/einf2480/model_parameters/soil_property/',\n",
       " 'InputPath': '/scratch-shared/ecoextreml/stemmus_scope/input/',\n",
       " 'OutputPath': '/scratch-shared/ecoextreml/stemmus_scope/output/',\n",
       " 'ForcingPath': '/projects/0/einf2480/forcing/plumber2_data/',\n",
       " 'ForcingFileName': 'FI-Hyy_1996-2014_FLUXNET2015_Met.nc',\n",
       " 'VegetationPropertyPath': '/projects/0/einf2480/model_parameters/vegetation_property/',\n",
       " 'DurationSize': '17520'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the user must provide the correct path\n",
    "# path to config file\n",
    "config_file_path = Path(root_path_to_model, \"./config_file_snellius.txt\")\n",
    "# create an empty dict\n",
    "config = {}\n",
    "with open(config_file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        (key, val) = line.split(\"=\")\n",
    "        config[key] = val.rstrip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit config\n",
    "config[\"DurationSize\"] = \"20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create input directories, prepare input files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dir(station_name):\n",
    "    \"\"\"Create input directory and prepare input files\n",
    "    \"\"\"\n",
    "    # get start time with the format Y-M-D-HM\n",
    "    timestamp = time.strftime('%Y%m%d_%H%M')\n",
    "    # create input directory\n",
    "    work_dir = Path(config[\"InputPath\"], station_name + '_' + timestamp)\n",
    "    Path(work_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Prepare work directory {work_dir} for the station: {station_name}\")\n",
    "    # copy model parameters to work directory\n",
    "    shutil.copytree(config[\"VegetationPropertyPath\"], work_dir, dirs_exist_ok=True)\n",
    "    # update config file for ForcingFileName and InputPath\n",
    "    config_file_path = Path(work_dir, f\"{station_name}_{timestamp}_config.txt\")\n",
    "    with open(config_file_path, 'w') as f:\n",
    "        for i in config.keys():\n",
    "            if i == \"ForcingFileName\":\n",
    "                f.write(i + \"=\" + ncfile.stem + \".nc\" + \"\\n\")\n",
    "            elif i == \"InputPath\":\n",
    "                f.write(i + \"=\" + str(work_dir) + \"/\" + \"\\n\")\n",
    "            else:\n",
    "                f.write(i + \"=\" + config[i] + \"\\n\")\n",
    "\n",
    "    return work_dir, config_file_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare work directory for the station: NL-Hor\n",
      "Prepare work directory for the station: ZA-Kru\n"
     ]
    }
   ],
   "source": [
    "# specify the forcing filenames\n",
    "# forcing_filenames_list is by default none, if full_run is true, then all stations with forcing\n",
    "# listed in the ForcingPath will be used.\n",
    "forcing_filenames_list = [\"NL-Hor_2008-2011_FLUXNET2015_Met.nc\",\n",
    " \"ZA-Kru_2000-2002_FLUXNET2015_Met.nc\"]\n",
    "\n",
    "full_run = False\n",
    "if full_run:\n",
    "    forcing_filenames_list = Path(config[\"ForcingPath\"]).iterdir()\n",
    "\n",
    "config_path_dict = {}\n",
    "work_dir_dict = {}\n",
    "for ncfile in forcing_filenames_list:\n",
    "    station_name = ncfile.stem.split('_')[0]\n",
    "    work_dir_dict[station_name], config_path_dict[station_name] = input_dir(station_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening log file:  /gpfs/home3/yangl/processing/out/java.log.8605\n",
      "Reading config from /scratch-shared/ecoextreml/stemmus_scope/test/input/ZA-Kru_2022-05-10-1135/ZA-Kru_2022-05-10-1135_config.txt\n",
      "\n",
      " The calculations start now \n",
      "Opening log file:  /gpfs/home3/yangl/processing/out/java.log.9641\n",
      "Reading config from /scratch-shared/ecoextreml/stemmus_scope/test/input/NL-Hor_2022-05-10-1135/NL-Hor_2022-05-10-1135_config.txt\n",
      "\n",
      " The calculations start now \n",
      " The calculations end now \r"
     ]
    }
   ],
   "source": [
    "# generate a text file\n",
    "root_path = Path().resolve().parent\n",
    "str.split(\"/\")[-1]\n",
    "for ncfile in forcing_filenames_list:\n",
    "    station_name = ncfile.stem.split(\"_\")[0]\n",
    "    path_to_config = config_path_dict[station_name]\n",
    "    # set matlab log dir to slurm, otherwise java.log files are created in user home dir\n",
    "    os.environ['MATLAB_LOG_DIR'] = work_dir_dict[station_name]\n",
    "    # run the model\n",
    "    print(f\"Run STEMMUS-SCOPE for the station: {station_name}\")\n",
    "    result = subprocess.run([f\"exe/STEMMUS_SCOPE {path_to_config}\"], cwd = root_path_to_model, shell=True)\n",
    "    result.check_returncode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create output directories, prepare output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch-shared/ecoextreml/stemmus_scope/test/output/ZA-Kru_2022-05-10-1135/ECdata.csv\n",
      "Reading variable metadata from /home/yangl/STEMMUS_SCOPE/utils/csv_to_nc/Variables_will_be_in_NetCDF_file.csv\n",
      "Creating /scratch-shared/ecoextreml/stemmus_scope/test/output/ZA-Kru_2022-05-10-1135/ZA-Kru_2022-05-10-1135_STEMMUS_SCOPE.nc \n",
      "Reading data from file: radiation.csv\n",
      "Reading data from file: fluxes.csv\n",
      "Reading data from file: surftemp.csv\n",
      "Reading data from file: Sim_Temp.csv\n",
      "Reading data from file: Sim_Theta.csv\n",
      "Reading data from file: aerodyn.csv\n",
      "Reading data from file: ECdata.csv\n",
      "Done writing /scratch-shared/ecoextreml/stemmus_scope/test/output/ZA-Kru_2022-05-10-1135/ZA-Kru_2022-05-10-1135_STEMMUS_SCOPE.nc\n",
      "/scratch-shared/ecoextreml/stemmus_scope/test/output/NL-Hor_2022-05-10-1136/ECdata.csv\n",
      "Reading variable metadata from /home/yangl/STEMMUS_SCOPE/utils/csv_to_nc/Variables_will_be_in_NetCDF_file.csv\n",
      "Creating /scratch-shared/ecoextreml/stemmus_scope/test/output/NL-Hor_2022-05-10-1136/NL-Hor_2022-05-10-1136_STEMMUS_SCOPE.nc \n",
      "Reading data from file: radiation.csv\n",
      "Reading data from file: fluxes.csv\n",
      "Reading data from file: surftemp.csv\n",
      "Reading data from file: Sim_Temp.csv\n",
      "Reading data from file: Sim_Theta.csv\n",
      "Reading data from file: aerodyn.csv\n",
      "Reading data from file: ECdata.csv\n",
      "Done writing /scratch-shared/ecoextreml/stemmus_scope/test/output/NL-Hor_2022-05-10-1136/NL-Hor_2022-05-10-1136_STEMMUS_SCOPE.nc\n"
     ]
    }
   ],
   "source": [
    "# convert csv files to nc files\n",
    "path_to_utils = Path(root_path_to_model, \"utils/csv_to_nc\")\n",
    "for ncfile in forcing_filenames_list:\n",
    "    station_name = ncfile.stem.split(\"_\")[0]\n",
    "    path_to_config = config_path_dict[station_name]\n",
    "    result = subprocess.run([\"python\", Path(path_to_utils, \"generate_netcdf_files.py\"),\n",
    "         \"--config_file\", path_to_config, \"--variable_file\",\n",
    "         Path(path_to_utils, \"Variables_will_be_in_NetCDF_file.csv\")])\n",
    "    result.check_returncode()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28b136f154b3384fcb2854e5626613232692c304dbc5315064ef4c9363104a2c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
